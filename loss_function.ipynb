{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "损失函数实验 - 神经网络学习路径第7步\n",
    "\n",
    "本 Notebook 引入损失函数概念，为神经网络的训练优化提供目标函数。\n",
    "在前面的 Notebook 中，我们已经构建了完整的前馈神经网络架构：\n",
    "- 从单个神经元到多层网络\n",
    "- 抽象出 Layer 和 Network 类\n",
    "- 引入 Softmax 激活函数用于分类\n",
    "\n",
    "现在我们需要定义\"好坏\"的衡量标准 - 损失函数，它将：\n",
    "1. 衡量模型预测与真实标签之间的差距\n",
    "2. 为后续的反向传播和参数优化提供梯度信息\n",
    "3. 指导网络学习正确的分类边界\n",
    "\n",
    "主要内容：\n",
    "- 生成二分类数据集（圆形边界分类问题）\n",
    "- 可视化数据分布\n",
    "- 实现常用的损失函数（如交叉熵损失）\n",
    "- 观察损失函数如何量化预测质量\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8fa2e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成用于分类的数据，并为每个数据点打标签\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "def tag_entry(x,y):\n",
    "    if x**2+y**2<1:\n",
    "        tag=0\n",
    "    else:\n",
    "        tag=1\n",
    "    return tag\n",
    "\n",
    "def create_data(Number_of_Data):\n",
    "    entry_list=[]\n",
    "    for i in range (Number_of_Data):\n",
    "        x=random.uniform(-2,2)\n",
    "        y=random.uniform(-2,2)\n",
    "        tag=tag_entry(x,y)\n",
    "        entry_list.append([x,y,tag])\n",
    "    return np.array(entry_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad52af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化\n",
    "def plot_data(data,title):\n",
    "    colors=[]\n",
    "    for i in data[:,2]:\n",
    "        if i==0:\n",
    "            colors.append(\"orange\")\n",
    "        else:\n",
    "            colors.append(\"blue\")\n",
    "    plt.scatter(data[:,0],data[:,1],c=colors)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b7bcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_ReLU(inputs):\n",
    "    return np.maximum(0,inputs)\n",
    "\n",
    "def activation_softmax(inputs):\n",
    "    max_value=np.max(inputs,axis=1,keepdims=True)\n",
    "    slided_inputs=inputs-max_value\n",
    "    exp_values=np.exp(slided_inputs)\n",
    "    norm_base=np.sum(exp_values,axis=1,keepdims=True)\n",
    "    norm_values=exp_values/norm_base\n",
    "    return norm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1545b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=np.random.randn(n_inputs,n_neurons)  \n",
    "        self.biases=np.random.randn(n_neurons)  \n",
    "\n",
    "    def forward(self,inputs):\n",
    "        self.sum=np.dot(inputs,self.weights)+self.biases  \n",
    "        return self.sum  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6db14314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network:\n",
    "    def __init__(self,network_shape):\n",
    "        self.shape=network_shape\n",
    "        self.layers=[]\n",
    "        for i in range(len(network_shape)-1):\n",
    "            layer=Layer(network_shape[i],network_shape[i+1])\n",
    "            self.layers.append(layer)\n",
    "    #前馈运算\n",
    "    def network_forward(self,inputs):\n",
    "        outputs=[inputs]\n",
    "        for i in range(len(self.layers)):\n",
    "            layer_output=self.layers[i].forward(outputs[i])\n",
    "            if i==len(self.layers)-1:\n",
    "                layer_output=activation_softmax(layer_output)\n",
    "            else:\n",
    "                layer_output=activation_ReLU(layer_output)\n",
    "            outputs.append(layer_output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9779fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分类函数\n",
    "def classify(probabilities):\n",
    "    classification=np.rint(probabilities[:,1])\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1011f",
   "metadata": {},
   "source": [
    "在这个代码中：\n",
    "real_matrix[:,1]=real.flatten() - 将真实标签放在第二列（索引1）\n",
    "real_matrix[:,0]=1-real - 第一列是标签的补集\n",
    "\n",
    "这意味着：\n",
    "第一列对应标签0的概率（A类）\n",
    "第二列对应标签1的概率（B类）\n",
    "\n",
    "所以如果你的神经网络输出是[P(A类), P(B类)]，那么：\n",
    "当真实标签是0时，one-hot编码应该是[1, 0]\n",
    "当真实标签是1时，one-hot编码应该是[0, 1]\n",
    "\n",
    "关键：你需要确保神经网络的输出顺序与这个one-hot编码的约定一致。如果你的网络第一个输出表示A类，第二个输出表示B类，那么标签0应该对应A类，标签1应该对应B类。\n",
    "这个约定必须在整个训练过程中保持一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c3f6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def precise_loss_function(predicted,real):\n",
    "    \"\"\"\n",
    "    精确损失函数\n",
    "    \n",
    "    参数:\n",
    "    predicted: 预测值矩阵，形状为(n_samples, 2)\n",
    "    real: 真实标签，形状为(1, n_samples)或(n_samples,)\n",
    "    \n",
    "    返回:\n",
    "    损失值数组，形状为(n_samples,)\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建真实标签的one-hot编码矩阵\n",
    "    real_matrix=np.zeros((len(real),2))  # 使用是len(real)\n",
    "    real_matrix[:,1]=real.flatten()  # 使用flatten()将(1,5)转换为(5,)，赋值给第二列（正类）\n",
    "    real_matrix[:,0]=1-real  # 第一列为负类（1-正类标签）\n",
    "    print(real_matrix)\n",
    "    \n",
    "    # 计算预测值与真实标签的点积，沿axis=1求和\n",
    "    product=np.sum(predicted*real_matrix,axis=1)\n",
    "    \n",
    "    # 返回损失值：1减去点积\n",
    "    return 1-product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c79b04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[0.00151378 0.99931667 0.00122939 0.0023873  0.46932377]\n"
     ]
    }
   ],
   "source": [
    "Number_of_Data=5\n",
    "data=create_data(Number_of_Data)\n",
    "\n",
    "inputs=data[:,0:2]\n",
    "tagets=data[:,2]\n",
    "\n",
    "net=Network([2,3,4,5,2])\n",
    "outputs=net.network_forward(inputs)\n",
    "classification=classify(outputs[-1])\n",
    "\n",
    "precise_loss_function(outputs[-1],tagets)\n",
    "print(precise_loss_function(outputs[-1],tagets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
