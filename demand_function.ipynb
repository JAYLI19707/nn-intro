{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8fa2e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成用于分类的数据，并为每个数据点打标签\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "\n",
    "def tag_entry(x,y):\n",
    "    if x**2+y**2<1:\n",
    "        tag=0\n",
    "    else:\n",
    "        tag=1\n",
    "    return tag\n",
    "\n",
    "def create_data(Number_of_Data):\n",
    "    entry_list=[]\n",
    "    for i in range (Number_of_Data):\n",
    "        x=random.uniform(-2,2)\n",
    "        y=random.uniform(-2,2)\n",
    "        tag=tag_entry(x,y)\n",
    "        entry_list.append([x,y,tag])\n",
    "    return np.array(entry_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad52af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化\n",
    "def plot_data(data,title):\n",
    "    colors=[]\n",
    "    for i in data[:,2]:\n",
    "        if i==0:\n",
    "            colors.append(\"orange\")\n",
    "        else:\n",
    "            colors.append(\"blue\")\n",
    "    plt.scatter(data[:,0],data[:,1],c=colors)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b7bcc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_ReLU(inputs):\n",
    "    return np.maximum(0,inputs)\n",
    "\n",
    "def activation_softmax(inputs):\n",
    "    max_value=np.max(inputs,axis=1,keepdims=True)\n",
    "    slided_inputs=inputs-max_value\n",
    "    exp_values=np.exp(slided_inputs)\n",
    "    norm_base=np.sum(exp_values,axis=1,keepdims=True)\n",
    "    norm_values=exp_values/norm_base\n",
    "    return norm_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1545b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=np.random.randn(n_inputs,n_neurons)  \n",
    "        self.biases=np.random.randn(n_neurons)  \n",
    "\n",
    "    def forward(self,inputs):\n",
    "        self.sum=np.dot(inputs,self.weights)+self.biases  \n",
    "        return self.sum  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6db14314",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Network:\n",
    "    def __init__(self,network_shape):\n",
    "        self.shape=network_shape\n",
    "        self.layers=[]\n",
    "        for i in range(len(network_shape)-1):\n",
    "            layer=Layer(network_shape[i],network_shape[i+1])\n",
    "            self.layers.append(layer)\n",
    "    #前馈运算\n",
    "    def network_forward(self,inputs):\n",
    "        outputs=[inputs]\n",
    "        for i in range(len(self.layers)):\n",
    "            layer_output=self.layers[i].forward(outputs[i])\n",
    "            if i==len(self.layers)-1:\n",
    "                layer_output=activation_softmax(layer_output)\n",
    "            else:\n",
    "                layer_output=activation_ReLU(layer_output)\n",
    "            outputs.append(layer_output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9779fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分类函数\n",
    "def classify(probabilities):\n",
    "    classification=np.rint(probabilities[:,1])\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c3f6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precise_loss_function(predicted,real):\n",
    "\n",
    "    # 创建真实标签的one-hot编码矩阵\n",
    "    real_matrix=np.zeros((len(real),2))  # 使用是len(real)\n",
    "    real_matrix[:,1]=real.flatten()  # 使用flatten()将(1,5)转换为(5,)，赋值给第二列（正类）\n",
    "    real_matrix[:,0]=1-real  # 第一列为负类（1-正类标签）\n",
    "    print(\"真实标签补全矩阵:\\n\",real_matrix)\n",
    "    \n",
    "    # 计算预测值与真实标签的点积，沿axis=1求和\n",
    "    product=np.sum(predicted*real_matrix,axis=1)\n",
    "    \n",
    "    # 返回损失值：1减去点积\n",
    "    return 1-product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1199ed",
   "metadata": {},
   "source": [
    "举例说明：\n",
    "假设有一个样本，真实标签是1（正类），预测概率是[0.8, 0.2]：\n",
    "转换为one-hot：target = [0, 1]\n",
    "检查预测：点积 = 0×0.8 + 1×0.2 = 0.2 < 0.5（预测错误）\n",
    "\n",
    "计算demands：\n",
    "原始误差：[0, 1] - 0.5 = [-0.5, 0.5]\n",
    "放大误差：[-0.5, 0.5] × 2 = [-1, 1]\n",
    "结果：返回[-1, 1]，意思是\"强烈减少负类输出，强烈增加正类输出\"\n",
    "\n",
    "如果预测是[0.2, 0.8]（正确），点积=0.8>0.5，则返回[0, 0]（无需调整）。\n",
    "放大的意义：将-0.5到0.5的微弱信号放大到-1到1，让权重调整更显著"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08b881d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_layer_preAct_demands(predicted_value,target_value):\n",
    "    \"\"\"\n",
    "    计算最终层激活前的需求值（demands），用于反向传播的梯度计算\n",
    "    \n",
    "    参数:\n",
    "    predicted_value: 预测概率值，形状为 (m, 2)，每行为一个样本的[负类概率, 正类概率]\n",
    "    target_value: 真实标签，形状为 (m,)，值为0或1\n",
    "    \n",
    "    返回:\n",
    "    target: 梯度信号向量，形状为 (m, 2)\n",
    "            - 如果预测正确：返回 [0, 0]（无需调整）\n",
    "            - 如果预测错误：返回放大的误差向量，指导权重如何调整\n",
    "    \"\"\"\n",
    "    # 创建one-hot编码矩阵\n",
    "    target=np.zeros((len(target_value),2))\n",
    "    target[:,1]=target_value  # 第二列为正类标签\n",
    "    target[:,0]=1-target_value  # 第一列为负类标签（1-正类）\n",
    "    \n",
    "    # 遍历每个样本\n",
    "    for i in range(len(predicted_value)):\n",
    "        # 计算预测值与真实标签的点积，判断预测是否正确\n",
    "        if np.dot(target[i],predicted_value[i])>0.5:\n",
    "            # 预测正确：点积>0.5，设置为零向量（无需调整权重）\n",
    "            target[i]=np.array([0,0])\n",
    "        else:\n",
    "            # 预测错误：计算放大的误差向量\n",
    "            # (target-0.5)*2 将-0.5~0.5的误差放大到-1~1，增强梯度信号\n",
    "            target[i]=(target[i]-0.5)*2\n",
    "    return target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce1a9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测值 (predicted_value):\n",
      "[[0.  1. ]\n",
      " [0.5 0.5]\n",
      " [0.2 0.8]\n",
      " [0.7 0.3]\n",
      " [0.9 0.1]]\n",
      "\n",
      "真实标签 (target_value):\n",
      "[1 0 1 0 1]\n",
      "\n",
      "需求值:\n",
      "[[ 0.  0.]\n",
      " [ 1. -1.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [-1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# 测试需求函数\n",
    "# 修复：np.array() 需要嵌套列表来创建二维数组\n",
    "predicted_value = np.array([[0., 1],\n",
    "                            [0.5, 0.5],\n",
    "                            [0.2, 0.8], \n",
    "                            [0.7, 0.3],\n",
    "                            [0.9, 0.1]])\n",
    "\n",
    "target_value = np.array([1, 0, 1, 0, 1])\n",
    "\n",
    "print(\"预测值 (predicted_value):\")\n",
    "print(predicted_value)\n",
    "print(\"\\n真实标签 (target_value):\")\n",
    "print(target_value)\n",
    "print(\"\\n需求值:\")\n",
    "print(get_final_layer_preAct_demands(predicted_value,target_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8bf995",
   "metadata": {},
   "source": [
    "浅拷贝（Shallow Copy）：\n",
    "只复制对象的第一层结构\n",
    "嵌套对象仍然是引用，修改嵌套内容会影响原对象\n",
    "使用：copy.copy() 或 list.copy()\n",
    "\n",
    "深拷贝（Deep Copy）：\n",
    "递归复制所有层级的对象\n",
    "完全独立的副本，修改任何层级都不会影响原对象\n",
    "使用：copy.deepcopy()\n",
    "\n",
    "对于NumPy数组：\n",
    "array.copy() 通常就足够了（NumPy数组元素是基本数据类型）\n",
    "copy.deepcopy() 在这里有些过度，但确保了完全隔离\n",
    "\n",
    "第一层结构指对象本身的直接属性，不包括嵌套对象的内容。\n",
    "例子：\n",
    "第一层：列表本身 [_, _]\n",
    "第二层：嵌套的子列表 [1, 2] 和 [3, 4]\n",
    "\n",
    "浅拷贝结果：\n",
    "复制了外层列表结构（创建新的列表对象）\n",
    "但子列表仍然是引用，shallow[0] 和 original[0] 指向同一个 [1, 2]\n",
    "修改 shallow[0][0] = 99 会同时改变 original[0][0]\n",
    "\n",
    "简单说： 只复制\"容器\"，不复制\"容器里的东西\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79b04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原数据data:\n",
      " [[ 0.95766849 -0.2148687   0.        ]\n",
      " [ 1.23720219 -1.32012822  1.        ]\n",
      " [ 0.71617953  1.18114183  1.        ]\n",
      " [ 1.68150705  0.58082246  1.        ]\n",
      " [ 1.79711348 -1.25986425  1.        ]]\n",
      "真实标签补全矩阵:\n",
      " [[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "loss:\n",
      " [0.05635063 0.9557253  0.8461802  0.84862233 0.9557253 ]\n",
      "\n",
      "demands:\n",
      " [[ 0.  0.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "Number_of_Data=5\n",
    "data=create_data(Number_of_Data)\n",
    "print(\"原数据data:\\n\",data)\n",
    "inputs=data[:,0:2]\n",
    "# 使用 copy.deepcopy() 创建目标标签的深拷贝\n",
    "# 原因：如果直接使用 tagets = data[:,2]，那么 tagets 只是 data[:,2] 的一个引用\n",
    "# 当后续代码修改 tagets 时，原始的 data 数组也会被修改，这可能导致：\n",
    "# 1. 数据污染：原始训练数据被意外修改\n",
    "# 2. 调试困难：多次运行代码时结果不一致\n",
    "# 3. 内存共享问题：多个变量指向同一内存地址\n",
    "# 使用深拷贝确保 tagets 是独立的副本，保护原始数据不被修改\n",
    "tagets=copy.deepcopy(data[:,2])\n",
    "\n",
    "net=Network([2,3,4,5,2])\n",
    "outputs=net.network_forward(inputs)\n",
    "classification=classify(outputs[-1])\n",
    "\n",
    "loss=precise_loss_function(outputs[-1],tagets)\n",
    "print(\"\\nloss:\\n\",loss)\n",
    "demands=get_final_layer_preAct_demands(outputs[-1],tagets)\n",
    "print(\"\\ndemands:\\n\",demands)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
