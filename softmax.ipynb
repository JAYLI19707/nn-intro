{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb91732",
   "metadata": {},
   "source": [
    "Softmax函数是一种常用于多分类问题的激活函数。它可以将一个包含任意实数的向量转换为概率分布形式的向量，使得每个元素的取值范围在0到1之间，并且所有元素的和为1。\n",
    "\n",
    "Softmax函数常用于神经网络的输出层，用于表示各类别的预测概率。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a57d3fa",
   "metadata": {},
   "source": [
    "这也是softmax中常见的数学性质：  \n",
    "假设有三个数a, b, c，且b-a = c-b = d（等间距），  \n",
    "则$$\\frac{\\exp(b)}{\\exp(a)} = exp(b-a) = exp(d)$$  \n",
    "    $$\\frac{exp(c)}{exp(b)} = exp(c-b) = exp(d)$$  \n",
    "所以等间距的指数比值是相等的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "904cb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_ReLU(inputs):\n",
    "    return np.maximum(0,inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "186a7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 该函数实现了Softmax激活函数，常用于多分类神经网络的输出层。\n",
    "# 输入参数inputs为二维数组（每行为一个样本，每列为一个类别的得分）。\n",
    "# 1. 首先，计算每一行的最大值max_value，用于数值稳定性处理，防止指数溢出。\n",
    "# 2. 用inputs减去max_value，得到slided_inputs。\n",
    "# 3. 对slided_inputs进行指数运算，得到exp_values。\n",
    "# 4. 对每一行的exp_values求和，得到归一化的分母norm_base。\n",
    "# 5. 用exp_values除以norm_base，得到每一行的概率分布norm_values。\n",
    "# 6. 返回归一化后的概率分布。\n",
    "\n",
    "def activation_softmax(inputs):\n",
    "    max_value=np.max(inputs,axis=1,keepdims=True)\n",
    "    slided_inputs=inputs-max_value\n",
    "    exp_values=np.exp(slided_inputs)\n",
    "    norm_base=np.sum(exp_values,axis=1,keepdims=True)\n",
    "    norm_values=exp_values/norm_base\n",
    "    return norm_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d54d3c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始矩阵：\n",
      "[[ 0.29504093  0.30678255 -0.60205285  0.85765438 -0.85088581]\n",
      " [ 0.09244222  0.22456618  0.7754452  -1.87735143 -0.37046899]]\n",
      "softmax结果：\n",
      "[[0.22258099 0.22520985 0.09075806 0.39068612 0.07076498]\n",
      " [0.20449906 0.2333845  0.40487013 0.02852468 0.12872163]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义softmax函数\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # 防止溢出\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# 生成2x5的矩阵\n",
    "matrix = np.random.randn(2, 5)\n",
    "print(\"原始矩阵：\")\n",
    "print(matrix)\n",
    "\n",
    "# 对矩阵应用softmax\n",
    "softmax_result = softmax(matrix)\n",
    "print(\"softmax结果：\")\n",
    "print(softmax_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfdf9f",
   "metadata": {},
   "source": [
    "### 以下是运行实现softmax的神经网络\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1ca8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#面向对象的层\n",
    "class Layer:\n",
    "    # 初始化函数,需要输入神经元个数和输入维度\n",
    "    # self.weights和self.biases是类的属性,需要用self.来定义\n",
    "    def __init__(self,n_inputs,n_neurons):\n",
    "        self.weights=np.random.randn(n_inputs,n_neurons)  # weights是每个神经元的权重矩阵\n",
    "        self.biases=np.random.randn(n_neurons)  # biases是每个神经元的偏置项\n",
    "\n",
    "    # 前向传播函数,需要输入数据\n",
    "    # self.sum和self.output是类的属性,需要用self.来定义\n",
    "    # inputs是函数的参数,直接使用即可\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        # 在Python中,当我们使用self.sum时,Python会自动为类创建一个名为sum的属性\n",
    "        # 这是Python的动态特性 - 可以在运行时动态添加属性\n",
    "        # 调用方法:\n",
    "        # 1. 在类的其他方法中可以直接用self.sum访问\n",
    "        # 2. 在类的外部可以用实例名.sum访问,比如Layer1.sum\n",
    "        self.sum=np.dot(inputs,self.weights)+self.biases  # 计算加权和\n",
    "        return self.sum  # 返回输出结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fca3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面是对上一层输出应用softmax激活函数的注释示例：\n",
    "# softmax激活函数常用于多分类问题的输出层，将神经网络的输出转换为概率分布。\n",
    "# 其主要思想是对每个类别的得分取指数后归一化，使所有类别的概率和为1。\n",
    "# 这样可以方便地解释输出为每个类别的概率，有助于分类决策。\n",
    "class Network:\n",
    "    def __init__(self,network_shape):\n",
    "        self.shape=network_shape\n",
    "        self.layers=[]\n",
    "        for i in range(len(network_shape)-1):\n",
    "            layer=Layer(network_shape[i],network_shape[i+1])\n",
    "            self.layers.append(layer)\n",
    "    #前馈运算\n",
    "    def network_forward(self,inputs):\n",
    "        outputs=[inputs]\n",
    "        for i in range(len(self.layers)):\n",
    "            layer_output=self.layers[i].forward(outputs[i])\n",
    "            if i==len(self.layers)-1:\n",
    "                layer_output=activation_softmax(layer_output)\n",
    "            else:\n",
    "                layer_output=activation_ReLU(layer_output)\n",
    "            outputs.append(layer_output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70f02fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0层输出:\n",
      "[[1. 2. 3.]]\n",
      "\n",
      "第1层输出:\n",
      "[[0.         3.92652249 0.34804878 5.55425097 5.60808204]]\n",
      "\n",
      "第2层输出:\n",
      "[[0.0024245 0.9975755]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试Network类\n",
    "import numpy as np\n",
    "\n",
    "# 定义激活函数\n",
    "def activation_ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def activation_softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "# 创建一个简单的网络结构，例如输入3个神经元，隐藏层5个神经元，输出2个神经元\n",
    "network_shape = [3, 5, 2]\n",
    "net = Network(network_shape)\n",
    "\n",
    "# 构造一个输入样本\n",
    "inputs = np.array([[1.0, 2.0, 3.0]])\n",
    "\n",
    "# 前向传播\n",
    "outputs = net.network_forward(inputs)\n",
    "\n",
    "# 打印每一层的输出\n",
    "for idx, out in enumerate(outputs):\n",
    "    print(f\"第{idx}层输出:\\n{out}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
